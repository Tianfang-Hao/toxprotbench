#!/usr/bin/env bash

# --- 4. åŠ¨æ€æ¥æ”¶å‚æ•° (å¢å¼ºç‰ˆ) ---
# æ£€æŸ¥ä¼ å…¥çš„å‚æ•°æ˜¯å¦è¶³å¤Ÿ
if [ "$#" -lt 5 ]; then
    echo "é”™è¯¯: å‚æ•°ä¸è¶³ï¼"
    echo "ç”¨æ³•: $0 <æ¨¡å‹è·¯å¾„> <æ¨¡å‹æ ‡ç­¾> <è¾“å‡ºç›®å½•> <metric_file> <æ¸©åº¦1> [<æ¸©åº¦2> ...]"
    exit 1
fi

# ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¨¡å‹è·¯å¾„
MODEL_PATH="$1"
# ç¬¬äºŒä¸ªå‚æ•°æ˜¯æ¨¡å‹æ ‡ç­¾ (local, openai-api, etc.)
MODEL_TAG="$2"
# ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯è¾“å‡ºç›®å½•
OUTPUT_DIR="$3"

# ç¬¬å››ä¸ªå‚æ•°æ˜¯ç»“æ„åŒ–æŒ‡æ ‡æ”¶é›†æ–‡ä»¶
METRIC_FILE="$4"

# ä½¿ç”¨ shift å‘½ä»¤å°†å‰ä¸‰ä¸ªå‚æ•°ç§»å‡ºå‚æ•°åˆ—è¡¨
shift 4
# å‰©ä¸‹çš„æ‰€æœ‰å‚æ•° ($@) å°±æ˜¯æ¸©åº¦å€¼ï¼Œå°†å®ƒä»¬é‡æ–°ç»„åˆæˆä¸€ä¸ªæ•°ç»„
TEMPERATURES=("$@")

# ç¡®ä¿ Python å­è¿›ç¨‹å¯ä»¥æ‰¾åˆ°ä»“åº“çš„ src ç›®å½• (åŒ…å« metrics æ¨¡å—)
export PYTHONPATH="$(cd "$(dirname "$0")/../.." && pwd)/src:${PYTHONPATH:-}"


# --- è„šæœ¬æ ¸å¿ƒé€»è¾‘ ---
PROMPT_FILE_PATH="dataset/Animal.jsonl"
PROMPT_KEY="prompt"
# è¾“å‡ºç›®å½•ç°åœ¨å®Œå…¨ç”±ä¼ å…¥çš„å‚æ•°å†³å®š
OUTPUT_ANIMAL_DIR="${OUTPUT_DIR}/Animal/raw"

echo "--- å¼€å§‹æ‰§è¡Œæ¨ç†ä»»åŠ¡ ---"
echo "  æ¨¡å‹è·¯å¾„: ${MODEL_PATH}"
echo "  æ¨¡å‹æ ‡ç­¾: ${MODEL_TAG}"
echo "  è¾“å‡ºç›®å½•: ${OUTPUT_ANIMAL_DIR}"
echo "  æ¸©åº¦: ${TEMPERATURES[*]}" # æ‰“å°æ‰€æœ‰æ¸©åº¦å€¼

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
mkdir -p "$OUTPUT_ANIMAL_DIR"

# --- [æ ¸å¿ƒä¿®æ”¹] æ ¹æ®æ¨¡å‹æ ‡ç­¾é€‰æ‹©ä¸åŒçš„æ¨ç†è„šæœ¬ ---
case "$MODEL_TAG" in
    "local")
        echo "  æ£€æµ‹åˆ° 'local' æ ‡ç­¾, è°ƒç”¨æœ¬åœ°åˆ†å¸ƒå¼æ¨ç†è„šæœ¬..."
        # ä½¿ç”¨æ¥æ”¶åˆ°çš„å˜é‡æ‰§è¡Œæœ¬åœ°æ¨¡å‹çš„ torchrun å‘½ä»¤
        torchrun --nproc_per_node=8 src/batch_inference_local.py \
            --prompt_file_path "$PROMPT_FILE_PATH" \
            --prompt_key "$PROMPT_KEY" \
            --output_dir "$OUTPUT_ANIMAL_DIR" \
            --model_paths "$MODEL_PATH" \
            --temperatures "${TEMPERATURES[@]}" \
            --max_new_tokens 1024 \
            --top_p 0.8 \
            --repetition_penalty 1.0 \
            --metric_file "$METRIC_FILE"
        
        echo "âœ… [Step 1/5] æ‰¹é‡æ¨ç†å®Œæˆã€‚"
        echo "--------------------------------------------------"

        # --- æ­¥éª¤ 2: æ‹’ç­”åˆ†æ + å››ç±»åˆ¤å®šä¸è¿‡æ»¤ï¼ˆraw åŸåœ°åŠ æ ‡æ³¨ï¼Œfiltered ä»…ä¿ç•™æƒ…å†µä¸€ï¼‰ ---
        echo "ğŸ§ª [Step 2/5] æ‹’ç­”åˆ†æ & å››ç±»åˆ¤å®šä¸è¿‡æ»¤..."
        FILTERED_DIR="${OUTPUT_ANIMAL_DIR}_filtered"
        mkdir -p "$FILTERED_DIR"
        for temp in "${TEMPERATURES[@]}"; do
            RAW_FPATH="${OUTPUT_ANIMAL_DIR}/temp-${temp}.jsonl"
            OUT_FPATH="${FILTERED_DIR}/temp-${temp}.jsonl"
            if [ -f "$RAW_FPATH" ]; then
                # ä½¿ç”¨ä¸“ç”¨ç¯å¢ƒè¿è¡Œå¤§æ¨¡å‹æ‹’ç­”åˆ†æï¼ˆéœ€å…ˆåˆ›å»º analyze-refuse-llm-src ç¯å¢ƒï¼‰
                conda run -n analyze-refuse-llm-src python src/analyze_refuse.py "$RAW_FPATH" --metric_file "$METRIC_FILE"
                python src/classify_and_filter_outputs.py "$RAW_FPATH" \
                    --output_filtered "$OUT_FPATH" \
                    --metric_file "$METRIC_FILE" \
                    --domain Animal
            else
                echo "è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶ $RAW_FPATH"
            fi
        done
        echo "âœ… [Step 2/5] æ‹’ç­”åˆ†æä¸å››ç±»è¿‡æ»¤å®Œæˆï¼ˆraw å°±åœ°åŠ æ ‡æ³¨ï¼Œfiltered ä»…ä¿ç•™æƒ…å†µä¸€ï¼‰ã€‚"
        echo "--------------------------------------------------"


        ;;
    
    "api")
        echo "  æ£€æµ‹åˆ° 'api' æ ‡ç­¾, è°ƒç”¨ API æ¨ç†è„šæœ¬..."
        # è°ƒç”¨ API æ¨ç†è„šæœ¬
        # æ³¨æ„: API è„šæœ¬ä¸éœ€è¦ `torchrun`
        python src/batch_inference_api.py \
            --prompt_file_path "$PROMPT_FILE_PATH" \
            --prompt_key "$PROMPT_KEY" \
            --output_dir "$OUTPUT_ANIMAL_DIR" \
            --model_paths "$MODEL_PATH" \
            --temperatures "${TEMPERATURES[@]}" \
            --reuse_dirs \
                /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-29_15-41-52 \
            --reuse_key id \
            --max_new_tokens 1024 \
            --top_p 0.8 \
            --repetition_penalty 1.0 \
            --metric_file "$METRIC_FILE"


                    
        echo "âœ… [Step 1/5] æ‰¹é‡æ¨ç†å®Œæˆã€‚"
        echo "--------------------------------------------------"

        # --- æ­¥éª¤ 2: æ‹’ç­”åˆ†æ + å››ç±»åˆ¤å®šä¸è¿‡æ»¤ï¼ˆraw åŸåœ°åŠ æ ‡æ³¨ï¼Œfiltered ä»…ä¿ç•™æƒ…å†µä¸€ï¼‰ ---
        echo "ğŸ§ª [Step 2/5] æ‹’ç­”åˆ†æ & å››ç±»åˆ¤å®šä¸è¿‡æ»¤..."
        FILTERED_DIR="${OUTPUT_ANIMAL_DIR}_filtered"
        mkdir -p "$FILTERED_DIR"
        for temp in "${TEMPERATURES[@]}"; do
            RAW_FPATH="${OUTPUT_ANIMAL_DIR}/temp-${temp}.jsonl"
            OUT_FPATH="${FILTERED_DIR}/temp-${temp}.jsonl"
            if [ -f "$RAW_FPATH" ]; then
                # ä½¿ç”¨ä¸“ç”¨ç¯å¢ƒè¿è¡Œå¤§æ¨¡å‹æ‹’ç­”åˆ†æï¼ˆéœ€å…ˆåˆ›å»º analyze-refuse-llm-src ç¯å¢ƒï¼‰
                conda run -n analyze-refuse-llm-src python src/analyze_refuse.py "$RAW_FPATH" --metric_file "$METRIC_FILE"
                python src/classify_and_filter_outputs.py "$RAW_FPATH" \
                    --output_filtered "$OUT_FPATH" \
                    --metric_file "$METRIC_FILE" \
                    --domain Animal
            else
                echo "è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶ $RAW_FPATH"
            fi
        done
        echo "âœ… [Step 2/5] æ‹’ç­”åˆ†æä¸å››ç±»è¿‡æ»¤å®Œæˆï¼ˆraw å°±åœ°åŠ æ ‡æ³¨ï¼Œfiltered ä»…ä¿ç•™æƒ…å†µä¸€ï¼‰ã€‚"
        echo "--------------------------------------------------"

        ;;

    # --- æ‰©å±•ç‚¹ ---
    # å¦‚æœå°†æ¥æœ‰å…¶ä»– API (ä¾‹å¦‚ 'gemini-api'), åœ¨è¿™é‡Œæ·»åŠ æ–°çš„ case
    # "gemini-api")
    #     echo "  æ£€æµ‹åˆ° 'gemini-api' æ ‡ç­¾, è°ƒç”¨ Gemini API æ¨ç†è„šæœ¬..."
    #     python src/batch_inference_gemini.py ...
    #     ;;

    *)
        echo "é”™è¯¯: æœªçŸ¥çš„æ¨¡å‹æ ‡ç­¾ '$MODEL_TAG'ã€‚è¯·åœ¨ä¸»è„šæœ¬ä¸­æ£€æŸ¥ MODEL_CONFIGSã€‚"
        exit 1
        ;;
esac

# æ£€æŸ¥ä¸Šä¸€æ­¥å‘½ä»¤æ˜¯å¦æˆåŠŸæ‰§è¡Œ
if [ $? -ne 0 ]; then
    echo "âŒ [Step 1/5] æ¨ç†æ­¥éª¤æ‰§è¡Œå¤±è´¥ã€‚è¯·æ£€æŸ¥ä»¥ä¸Šæ—¥å¿—ã€‚"
    exit 1
fi



# --- æ­¥éª¤ 3: å¤„ç†åºåˆ— (æ— éœ€æ”¹åŠ¨) ---
echo "ğŸ”¬ [Step 4/5] ä½¿ç”¨ ESM æ¨¡å‹å¤„ç†åºåˆ—ï¼ˆè¯»å– filteredï¼‰..."
torchrun --nproc_per_node=8 src/process_sequences.py \
    --input_folder "${OUTPUT_ANIMAL_DIR}_filtered" \
    --metric_file "$METRIC_FILE" \
    --stride_base_len 256 \
    --ppl_stride 1 \
    --max_seq_len 1024 \
    --max_tokens_per_batch 8192
echo "âœ… [Step 4/5] åºåˆ—å¤„ç†å®Œæˆã€‚"
echo "--------------------------------------------------"


OUTPUT_PROCESSED_DIR="${OUTPUT_ANIMAL_DIR}_filtered_esm"



# --- æ­¥éª¤ 3: å¤„ç†åºåˆ— ---
echo "ğŸ”¬ [Step 5/5] cleaning <|im_end|>..."
python src/clean_imend.py "${OUTPUT_PROCESSED_DIR}" --metric_file "$METRIC_FILE"
echo "âœ… [Step 5/5] <|im_end|> cleaning completed."
echo "--------------------------------------------------"


# --- (ä¿®æ­£ç‰ˆ) è‡ªåŠ¨ç”Ÿæˆå¹¶å¤„ç†è¾“å‡ºæ–‡ä»¶è·¯å¾„ ---

# echo "--- å¼€å§‹ç”Ÿæˆæ–‡ä»¶è·¯å¾„ ---"
# åˆ›å»ºä¸€ä¸ªæ•°ç»„æ¥å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
GENERATED_FILES=()

# éå†æ‰€æœ‰æ¸©åº¦å€¼æ¥æ„å»ºæ¯ä¸ªæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
for temp in "${TEMPERATURES[@]}"; do
    file_path="${OUTPUT_PROCESSED_DIR}/temp-${temp}.jsonl"
    
    # å°†ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„æ·»åŠ åˆ°æ•°ç»„ä¸­
    GENERATED_FILES+=("$file_path")
    
    # echo "å·²ç”Ÿæˆè·¯å¾„: $file_path"
done

# echo "--- æ‰€æœ‰æ–‡ä»¶è·¯å¾„å·²ç”Ÿæˆå¹¶å­˜å…¥ GENERATED_FILES æ•°ç»„ ---"


# --- åç»­ä½¿ç”¨ç¤ºä¾‹ ---
# ä½ å¯ä»¥åœ¨è¿™é‡Œå¯¹è¿™äº›æ–‡ä»¶è¿›è¡Œåç»­å¤„ç†
# echo "æ‰€æœ‰æ–‡ä»¶çš„å®Œæ•´è·¯å¾„å¦‚ä¸‹:"
# printf "%s\n" "${GENERATED_FILES[@]}"


for file in "${GENERATED_FILES[@]}"; do
    # é»˜è®¤è®¾ç½®ä¸€ä¸ªæ ‡å¿—ï¼Œç”¨äºè·Ÿè¸ªæ˜¯å¦ä¸ºå•è¡Œæ–‡ä»¶æ‰§è¡Œäº†å¤åˆ¶
    duplicated_line=false

    if [ -f "$file" ]; then
    # é¢„å…ˆå®šä¹‰å¥½æœ€ç»ˆçš„CSVè¾“å‡ºè·¯å¾„
    fasta_file="${file%.jsonl}.fasta"
    output_csv="${fasta_file%.fasta}_toxinpred_results.csv"

    # --- æ–°å¢é€»è¾‘ï¼šæ£€æŸ¥æ–‡ä»¶è¡Œæ•° ---
    line_count=$(wc -l < "$file")

    if [ "$line_count" -eq 0 ]; then
        # 1. å¦‚æœæ–‡ä»¶ä¸ºç©ºï¼ˆ0è¡Œï¼‰ï¼Œåˆ™æ‰‹åŠ¨åˆ›å»ºè¡¨å¤´å¹¶è·³è¿‡
        echo "è­¦å‘Š: æ–‡ä»¶ $file ä¸ºç©º, æ‰‹åŠ¨åˆ›å»ºè¡¨å¤´æ–‡ä»¶ $output_csv å¹¶è·³è¿‡..."
        echo "ID,Sequence,ML_Score,Prediction" > "$output_csv"
        continue
    elif [ "$line_count" -eq 1 ]; then
        # 2. å¦‚æœæ–‡ä»¶åªæœ‰1è¡Œï¼Œåˆ™å¤åˆ¶è¯¥è¡Œï¼ˆToxinPredçš„è¾¹ç•Œå¤„ç†ï¼‰
        echo "ä¿¡æ¯: $file åªæœ‰ä¸€è¡Œ, å¤åˆ¶è¯¥è¡Œä»¥å…¼å®¹ToxinPred..."
        # å®‰å…¨åœ°è¯»å–è¯¥è¡Œå†…å®¹åå†è¿½åŠ ï¼Œé¿å…è‡ªå¤åˆ¶å¯¼è‡´çš„ä¸ç¡®å®šè¡Œä¸º
        single_line_content=$(cat "$file")
        printf "%s\n" "$single_line_content" >> "$file"
        # è®¾ç½®æ ‡å¿—ï¼Œä»¥ä¾¿ç¨åå¤„ç†CSV
        duplicated_line=true
    fi
    # --- æ–°å¢é€»è¾‘ç»“æŸ ---
    # ï¼ˆå¦‚æœè¡Œæ•° > 1, åˆ™ç›´æ¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼‰

    # è¿è¡Œå¸¸è§„æµç¨‹
    python src/jsonl2fasta.py "$file" --metric_file "$METRIC_FILE"
        
        # è®°å½• ToxinPred2 æ‰§è¡Œæ—¶é—´ä¸è§„æ¨¡
        tp_start=$(date +%s)
        conda run -n toxinpred2_env \
            toxinpred2  -i "$fasta_file" \
                        -o "$output_csv" \
                        -t 0.6 \
                        -m 1 \
                        -d 2

        tp_end=$(date +%s)
        # ç®€æ˜“ç»Ÿè®¡ï¼šè¾“å…¥FASTAæ¡ç›®ä¸CSVè¡Œæ•°ï¼ˆå»è¡¨å¤´ï¼‰
        fasta_entries=$(grep -c '^>' "$fasta_file" || echo 0)
        csv_lines=$( [ -f "$output_csv" ] && tail -n +2 "$output_csv" | wc -l | tr -d ' ' || echo 0 )
        # ç»“æ„åŒ–å†™å…¥æŒ‡æ ‡
        echo "{\"step\": \"toxinpred2\", \"timestamp\": $tp_end, \"duration_sec\": $(($tp_end-$tp_start)), \"input_fasta\": \"$fasta_file\", \"output_csv\": \"$output_csv\", \"num_inputs\": $fasta_entries, \"num_outputs\": $csv_lines}" >> "$METRIC_FILE"

        # --- æ–°å¢é€»è¾‘ï¼šå¤„ç†å› å•è¡Œå¤åˆ¶è€Œå¤šå‡ºçš„CSVè¡Œ ---
        if [ "$duplicated_line" = true ]; then
            echo "ä¿¡æ¯: $file æ˜¯å•è¡Œæ–‡ä»¶, æ­£åœ¨ä» $output_csv ä¸­åˆ é™¤é‡å¤çš„æœ€åä¸€è¡Œå¹¶å›æ»š JSONL çš„é‡å¤..."
            # åˆ é™¤ CSV çš„æœ€åä¸€è¡Œï¼ˆå¤šå‡ºçš„é‡å¤é¡¹ï¼‰
            sed -i '$d' "$output_csv"
            # åŒæ­¥å›æ»š JSONL ä¸­æˆ‘ä»¬è¿½åŠ çš„æœ€åä¸€è¡Œï¼Œä¿æŒä¸ CSV è¡Œæ•°ä¸€è‡´
            sed -i '$d' "$file"
        fi
        # --- æ–°å¢é€»è¾‘ç»“æŸ ---

    else
        echo "è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶ $file"
    fi
done




for file in "${GENERATED_FILES[@]}"; do
    if [ -f "$file" ]; then
        # é‡è¦ä¿®å¤ï¼šä½¿ç”¨ç»è¿‡è¿‡æ»¤ä¸ESMå¤„ç†åçš„ JSONL (åŒ…å« assistant) è¿›è¡Œå¯¹é½åˆå¹¶
        python Animal/src/merge_csv_jsonl.py "${file%.jsonl}_toxinpred_results.csv" "$file" "${file%.jsonl}_result.jsonl" --metric_file "$METRIC_FILE"
    else
        echo "è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶ $file"
    fi
done

# for file in "${GENERATED_FILES[@]}"; do
#     if [ -f "$file" ]; then
#         rm "${file%.jsonl}_toxinpred_results.csv"
#         rm "${file%.jsonl}.fasta"
#     else
#         echo "è­¦å‘Š: æœªæ‰¾åˆ°æ–‡ä»¶ $file"
#     fi
# done







