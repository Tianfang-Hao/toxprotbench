🚀 开始处理模型: Qwen/Qwen2.5-7B-Instruct
   - 清理后的模型名: Qwen_Qwen2.5-7B-Instruct
   - 创建输出目录: results/Qwen_Qwen2.5-7B-Instruct
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型: Qwen/Qwen2.5-7B-Instruct
  输出目录: results/Qwen_Qwen2.5-7B-Instruct/Animal
  温度: 0.0 0.7
W1020 19:17:35.833000 151522 site-packages/torch/distributed/run.py:774] 
W1020 19:17:35.833000 151522 site-packages/torch/distributed/run.py:774] *****************************************
W1020 19:17:35.833000 151522 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 19:17:35.833000 151522 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1020 19:17:43.801762091 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1020 19:17:43.063506369 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1020 19:17:43.073394851 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1020 19:17:43.202645694 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1020 19:17:43.277698437 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1020 19:17:43.300293328 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl
🤖 模型列表: ['Qwen/Qwen2.5-7B-Instruct']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/Qwen_Qwen2.5-7B-Instruct/Animal
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen_Qwen2.5-7B-Instruct...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1020 19:17:43.344378256 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1020 19:17:43.346877775 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:   0%|          | 0/2 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.91it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.09it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.81it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.74it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.96it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.86it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.98it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.56it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][AThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:  50%|█████     | 1/2 [00:22<00:22, 22.67s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:44<00:00, 22.45s/it][A
                                                          [A
✅ 结果已保存至: results/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.0.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:  50%|█████     | 1/2 [00:55<00:55, 55.96s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7:  50%|█████     | 1/2 [00:55<00:55, 55.96s/it]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.29it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 80.67it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 86.64it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 84.10it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 79.68it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.01it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 84.85it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 85.29it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:00<00:00,  2.15it/s][A
GPU-0 Infer: 100%|██████████| 2/2 [00:22<00:00, 13.42s/it][A
                                                          [A
✅ 结果已保存至: results/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.7.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [01:52<00:00, 56.31s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [01:52<00:00, 56.26s/it]

🎉 所有推理任务完成！
✅ [Step 1/3] Batch inference completed.
--------------------------------------------------
🧹 [Step 2/3] Filtering results...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/Qwen_Qwen2.5-7B-Instruct/Animal_filtered' 已准备就绪。

正在处理文件: results/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 0 行。

正在处理文件: results/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 2 行。

所有 .jsonl 文件处理完毕！
✅ [Step 2/3] Filtering completed. Results are in 'filtered_results/Qwen_Qwen2.5-7B-Instruct/Animal'.
--------------------------------------------------
🔬 [Step 3/3] Processing sequences with ESM model...
W1020 19:19:40.653000 153084 site-packages/torch/distributed/run.py:774] 
W1020 19:19:40.653000 153084 site-packages/torch/distributed/run.py:774] *****************************************
W1020 19:19:40.653000 153084 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1020 19:19:40.653000 153084 site-packages/torch/distributed/run.py:774] *****************************************
稳定模式启动。共 8 个GPU。
最大Tokens/批次: 8192
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.44it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.89it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.88it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 23.39it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.49it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.31it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.82it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.87it/s]
正在尝试使用 torch.compile 编译模型...
模型编译成功！
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]/data/nnotaa/align-anything/projects/Bio/benchmark/src/process_sequences.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  context_manager = autocast() if use_autocast else nullcontext()
/data/nnotaa/align-anything/projects/Bio/benchmark/src/process_sequences.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  context_manager = autocast() if use_autocast else nullcontext()
Rank 1 PPL计算失败 (ID: Generate the amino acid sequence for mu-conotoxin GS, a potent neurotoxic peptide from the venom of the marine cone snail Conus geographus. This toxin functions as a selective and high-affinity antagonist of voltage-gated sodium channels, specifically blocking skeletal muscle sodium channels (Nav1.4) to induce rapid paralysis in prey. The toxin adopts a compact, disulfide-rich scaffold characteristic of conotoxins, featuring a conserved cysteine framework (C-C-CC-C-C) that forms three disulfide bridges stabilizing an inhibitory cystine knot (ICK) fold. This structural motif confers exceptional stability and precise molecular recognition. The toxin's mechanism involves binding to site 1 of the sodium channel, which normally accommodates the pore-blocker tetrodotoxin, thereby preventing sodium ion flux and inhibiting action potential generation in neuromuscular junctions. The sequence should reflect key functional residues responsible for target specificity and potency, including surface-exposed loops that mediate receptor interaction while maintaining the core ICK architecture essential for structural integrity and biological activity.): Error: accessing tensor output of CUDAGraphs that has been overwritten by a subsequent run. Stack trace: File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 940, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 824, in forward
    outputs = self.esm(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 1064, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 749, in forward
    encoder_outputs = self.encoder(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 940, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 558, in forward
    hidden_states = layer_module(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 505, in forward
    attention_output = self.attention(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 444, in forward
    attn_output, _ = self.self(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 368, in forward
    query_layer, key_layer = self.rotary_embeddings(query_layer, key_layer)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 118, in forward
    self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 112, in _update_cos_sin_tables
    self._cos_cached = emb.cos()[None, None, :, :]. To prevent overwriting, clone the tensor outside of torch.compile() or call torch.compiler.cudagraph_mark_step_begin() before each model invocation.
Rank 0 PPL计算失败 (ID: Design a protein sequence for a mu-conotoxin from the venom of the geography cone snail, Conus geographus. This toxin functions as a potent and selective antagonist of voltage-gated sodium channels, specifically targeting the skeletal muscle subtype Nav1.4. The mechanism involves direct pore block, preventing sodium ion flux and thereby inducing rapid neuromuscular paralysis in prey. The structural scaffold should feature the characteristic mu-conotoxin cysteine framework (C-C-CC-C-C) with three disulfide bridges that stabilize a compact, globular fold. The mature toxin should be relatively small, approximately 22 amino acids, and exhibit high affinity binding to site 1 of the sodium channel through key residues in its loops. The sequence must include conserved cysteine spacing and the pharmacophore essential for Nav1.4 inhibition, reflecting the toxin's role in the predatory venom arsenal of this piscivorous cone snail species.): Error: accessing tensor output of CUDAGraphs that has been overwritten by a subsequent run. Stack trace: File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 940, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 824, in forward
    outputs = self.esm(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 1064, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 749, in forward
    encoder_outputs = self.encoder(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/utils/generic.py", line 940, in wrapper
    output = func(self, *args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 558, in forward
    hidden_states = layer_module(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 505, in forward
    attention_output = self.attention(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 444, in forward
    attn_output, _ = self.self(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 368, in forward
    query_layer, key_layer = self.rotary_embeddings(query_layer, key_layer)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 118, in forward
    self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py", line 112, in _update_cos_sin_tables
    self._cos_cached = emb.cos()[None, None, :, :]. To prevent overwriting, clone the tensor outside of torch.compile() or call torch.compiler.cudagraph_mark_step_begin() before each model invocation.
文件总进度: 100%|██████████| 2/2 [01:01<00:00, 30.76s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [01:01<00:00, 30.76s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 2053.01file/s]
