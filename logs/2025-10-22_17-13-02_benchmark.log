🚀 开始处理模型: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380 (标签: local)
   - 清理后的模型名: _data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380
   - 创建输出目录: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380
  模型标签: local
  输出目录: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1022 17:13:04.823000 92346 site-packages/torch/distributed/run.py:774] 
W1022 17:13:04.823000 92346 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:13:04.823000 92346 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:13:04.823000 92346 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:13:12.550637845 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:13:12.583757093 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:13:13.805873535 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl
🤖 模型列表: ['/data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen2.5-7B-Instruct_slice_5380...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:13:13.957442027 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:13:13.063230731 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:13:13.144925760 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:13:13.161025883 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:13:13.164689730 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:   0%|          | 0/2 [00:01<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:01<00:01,  1.04s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/temp-0.0.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:  50%|█████     | 1/2 [01:06<01:06, 66.24s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7:  50%|█████     | 1/2 [01:06<01:06, 66.24s/it]
GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:22<00:22, 22.66s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [01:04<00:00, 33.82s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/temp-0.7.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [02:25<00:00, 73.69s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [02:25<00:00, 72.58s/it]

🎉 所有推理任务完成！
✅ [步骤 1/3] 批量推理完成。
--------------------------------------------------
🧹 [步骤 2/3] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered' 已准备就绪。

正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 5 行。

正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 5 行。

所有 .jsonl 文件处理完毕！
✅ [步骤 2/3] 过滤完成。结果位于 'filtered_results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal'.
--------------------------------------------------
🔬 [步骤 3/3] 使用 ESM 模型处理序列...
W1022 17:15:43.427000 93914 site-packages/torch/distributed/run.py:774] 
W1022 17:15:43.427000 93914 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:15:43.427000 93914 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:15:43.427000 93914 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.51it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.17it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.16it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.31it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.18it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.43it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 18.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 18.70it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.74it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.91it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:15:55.166102096 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:15:55.536648413 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:15:56.855585192 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:15:56.019317167 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:15:56.019728346 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:15:56.177919805 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:15:56.609630987 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:15:56.612333438 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:01,  1.40s/batch][A
                                              [A文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.40s/file, 处理中: temp-0.0.jsonl]文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.40s/file, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:19, 19.91s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:21<00:00, 12.29s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:21<00:00, 10.66s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 348.00file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 2349.09file/s]
摘要文件成功保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/summary_results.csv
✅ [步骤 3/3] 序列处理完成。
--------------------------------------------------
🔬 [Step 4/3] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 5
  修改行数: 5

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 5
  修改行数: 5

批量处理完毕，共处理 2 个文件。
✅ [Step 4/3] <|im_end|> cleaning completed.
--------------------------------------------------
开始转换文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0.jsonl -> results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 5 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:  results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0.fasta ; Model:  1 ; Threshold:  0.6
Output File:  results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0_toxinpred_results.csv ; Display:  2

开始转换文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7.jsonl -> results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 5 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:  results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7.fasta ; Model:  1 ; Threshold:  0.6
Output File:  results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7_toxinpred_results.csv ; Display:  2

开始处理...
  - 从 CSV 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']

处理完成！共合并 5 行记录。
结果已保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.0_result.jsonl
开始处理...
  - 从 CSV 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']

处理完成！共合并 5 行记录。
结果已保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal_filtered_esm/temp-0.7_result.jsonl
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380
  模型标签: local
  输出目录: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1022 17:18:09.421000 95365 site-packages/torch/distributed/run.py:774] 
W1022 17:18:09.421000 95365 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:18:09.421000 95365 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:18:09.421000 95365 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:18:23.427606801 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:18:23.482815620 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:18:24.629894995 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:18:24.703586455 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:18:24.728863969 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:18:24.737298464 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl
🤖 模型列表: ['/data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen2.5-7B-Instruct_slice_5380...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:18:24.756209502 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:18:24.783274413 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:   0%|          | 0/2 [00:02<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:01<00:01,  1.96s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:  50%|█████     | 1/2 [01:28<01:28, 88.38s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7:  50%|█████     | 1/2 [01:28<01:28, 88.38s/it]
GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:13<00:13, 13.89s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:19<00:00,  8.81s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [02:53<00:00, 86.75s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [02:53<00:00, 86.99s/it]

🎉 所有推理任务完成！
✅ [步骤 1/3] 批量推理完成。
--------------------------------------------------
🧹 [步骤 2/3] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered' 已准备就绪。

正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 5 行。

正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 7 行。

所有 .jsonl 文件处理完毕！
✅ [步骤 2/3] 过滤完成。结果位于 'filtered_results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria'.
--------------------------------------------------
🔬 [步骤 3/3] 使用 ESM 模型处理序列...
W1022 17:21:27.321000 96978 site-packages/torch/distributed/run.py:774] 
W1022 17:21:27.321000 96978 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:21:27.321000 96978 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:21:27.321000 96978 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.58it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.28it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.46it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.13it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.43it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.98it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.91it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.87it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.22it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.64it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.94it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.34it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.02it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.26it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.39it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.03it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:21:47.194834661 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:21:47.370904302 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:21:47.615199523 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:21:48.696292231 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:21:48.832080999 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:21:48.144022186 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:21:48.351067446 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:21:48.441507587 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:01,  1.60s/batch][A
                                              [A文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.60s/file, 处理中: temp-0.0.jsonl]文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.60s/file, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:53, 53.24s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:54<00:00, 31.97s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:54<00:00, 27.42s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 1161.54file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 10551.71file/s]
摘要文件成功保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm/summary_results.csv
✅ [步骤 3/3] 序列处理完成。
--------------------------------------------------
🔬 [Step 4/3] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 5
  修改行数: 5

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 7
  修改行数: 7

批量处理完毕，共处理 2 个文件。
✅ [Step 4/3] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
开始转换文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.jsonl -> results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.fasta

转换完成！
成功写入 13 个 FASTA 条目。
开始转换文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.jsonl -> results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.fasta

转换完成！
成功写入 13 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.fasta ---
读取了 13 条序列。
13
正在保存每个蛋白质的嵌入向量至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0_per_protein.h5
文件 results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.fasta 处理完毕，耗时 6.59 秒。

--- 正在处理文件: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.fasta ---
读取了 13 条序列。
13
正在保存每个蛋白质的嵌入向量至: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7_per_protein.h5
文件 results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.fasta 处理完毕，耗时 6.82 秒。

--- 所有文件处理完毕！总耗时 13.41 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(
/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(

Reading protein ID order from: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0.fasta
Found 13 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0_per_protein.h5

Running predictions...
Prediction counts: Counter({1: 13})

Saving results to: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0_per_protein.jsonl
Successfully saved 13 predictions.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(
/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
  warnings.warn(

Reading protein ID order from: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7.fasta
Found 13 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7_per_protein.h5

Running predictions...
Prediction counts: Counter({1: 13})

Saving results to: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7_per_protein.jsonl
Successfully saved 13 predictions.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']

处理完成！共合并 13 行记录。
结果已保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.0_result.jsonl
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']

处理完成！共合并 13 行记录。
结果已保存到: results/2025-10-22_17-13-02/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/temp-0.7_result.jsonl
✅ 模型 /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380 处理完成。
-----------------------------------------
🚀 开始处理模型: Qwen/Qwen2.5-7B-Instruct (标签: local)
   - 清理后的模型名: Qwen_Qwen2.5-7B-Instruct
   - 创建输出目录: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: Qwen/Qwen2.5-7B-Instruct
  模型标签: local
  输出目录: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1022 17:24:43.438000 98631 site-packages/torch/distributed/run.py:774] 
W1022 17:24:43.438000 98631 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:24:43.438000 98631 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:24:43.438000 98631 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:24:59.067830062 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl
🤖 模型列表: ['Qwen/Qwen2.5-7B-Instruct']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen_Qwen2.5-7B-Instruct...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:24:59.197459951 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:24:59.208795489 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:24:59.373025949 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1022 17:24:59.378966813 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:24:59.416573777 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:24:59.469979405 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:24:59.592854446 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:   0%|          | 0/2 [00:04<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 46.36it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 46.30it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 43.10it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.01it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 35.79it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 43.07it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 44.20it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 39.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 38.64it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00, 26.21it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 30.53it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][AThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:  50%|█████     | 1/2 [00:47<00:47, 47.89s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [01:16<00:00, 36.42s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.0.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:  50%|█████     | 1/2 [01:55<01:55, 115.01s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7:  50%|█████     | 1/2 [01:55<01:55, 115.01s/it]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 73.05it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 43.81it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 77.81it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 77.10it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 78.57it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 75.28it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 75.57it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 45.71it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:00<00:00,  1.87it/s][A
GPU-0 Infer: 100%|██████████| 2/2 [00:24<00:00, 14.32s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.7.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [02:52<00:00, 81.09s/it] 模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [02:52<00:00, 86.18s/it]

🎉 所有推理任务完成！
✅ [步骤 1/3] 批量推理完成。
--------------------------------------------------
🧹 [步骤 2/3] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered' 已准备就绪。

正在处理文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 0 行。

正在处理文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 1 行。

所有 .jsonl 文件处理完毕！
✅ [步骤 2/3] 过滤完成。结果位于 'filtered_results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal'.
--------------------------------------------------
🔬 [步骤 3/3] 使用 ESM 模型处理序列...
W1022 17:28:02.766000 100394 site-packages/torch/distributed/run.py:774] 
W1022 17:28:02.766000 100394 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:28:02.766000 100394 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:28:02.766000 100394 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.32it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.41it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.87it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.68it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.86it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.27it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.76it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.58it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.00it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.57it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.64it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.63it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.96it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.81it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:28:28.464344005 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:28:29.659880261 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:28:29.530940551 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:28:29.599353621 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:28:30.647523475 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:28:30.700816465 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:28:31.907541426 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:28:31.511072592 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:02,  2.77s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:02<00:00,  1.39s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:02<00:00,  1.39s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 904.04file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 4556.55file/s]
摘要文件成功保存到: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/summary_results.csv
✅ [步骤 3/3] 序列处理完成。
--------------------------------------------------
🔬 [Step 4/3] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 0
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 1
  修改行数: 1

批量处理完毕，共处理 2 个文件。
✅ [Step 4/3] <|im_end|> cleaning completed.
--------------------------------------------------
开始转换文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.jsonl -> results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 0 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 328, in main
    aac_comp(seq,'seq.aac')
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 58, in aac_comp
    zz = df.iloc[:,0]
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/pandas/core/indexing.py", line 1185, in __getitem__
    return self._getitem_tuple(key)
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/pandas/core/indexing.py", line 1691, in _getitem_tuple
    tup = self._validate_tuple_indexer(tup)
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/pandas/core/indexing.py", line 967, in _validate_tuple_indexer
    self._validate_key(k, i)
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/pandas/core/indexing.py", line 1593, in _validate_key
    self._validate_integer(key, axis)
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/pandas/core/indexing.py", line 1686, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.fasta -o results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0_toxinpred_results.csv -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:  results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0.fasta ; Model:  1 ; Threshold:  0.6
Output File:  results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0_toxinpred_results.csv ; Display:  2

开始转换文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.jsonl -> results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 1 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 330, in main
    prediction('seq.aac',nf_path+'/../model/RF_model.onnx','seq.pred' )
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 82, in prediction
    y_p_score1=sess.run([label_name], {input_name: X_test.astype(numpy.float32)})[0]
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 220, in run
    return self._sess.run(output_names, input_feed, run_options)
onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid rank for input: float_input Got: 1 Expected: 2 Please fix either the inputs/outputs or the model.

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.fasta -o results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7_toxinpred_results.csv -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:  results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7.fasta ; Model:  1 ; Threshold:  0.6
Output File:  results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7_toxinpred_results.csv ; Display:  2

开始处理...
  - 从 CSV 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.0_toxinpred_results.csv'
开始处理...
  - 从 CSV 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Animal_filtered_esm/temp-0.7_toxinpred_results.csv'
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: Qwen/Qwen2.5-7B-Instruct
  模型标签: local
  输出目录: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1022 17:29:18.686000 101764 site-packages/torch/distributed/run.py:774] 
W1022 17:29:18.686000 101764 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:29:18.686000 101764 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:29:18.686000 101764 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:29:35.646907642 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:29:35.733902877 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:29:35.741178173 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:29:35.778454489 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:29:35.862511822 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:29:35.105009120 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:29:35.173621028 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl
🤖 模型列表: ['Qwen/Qwen2.5-7B-Instruct']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen_Qwen2.5-7B-Instruct...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:29:35.319901429 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:   0%|          | 0/2 [00:03<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 46.01it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 39.23it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 39.02it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 42.91it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 42.62it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 41.19it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 45.40it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 41.11it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 37.44it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 37.22it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][AThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:  50%|█████     | 1/2 [00:32<00:32, 32.94s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [01:25<00:00, 44.51s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria/temp-0.0.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:  50%|█████     | 1/2 [01:46<01:46, 106.70s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7:  50%|█████     | 1/2 [01:46<01:46, 106.70s/it]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.65it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.45it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 38.58it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 38.25it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 40.45it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.45it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.28it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.44it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.30it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.18it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 37.04it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.83it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][A
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 37.07it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.83it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:01<00:01,  1.09s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:33<00:00, 19.59s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria/temp-0.7.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [02:57<00:00, 85.50s/it] 模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [02:57<00:00, 88.68s/it]

🎉 所有推理任务完成！
✅ [步骤 1/3] 批量推理完成。
--------------------------------------------------
🧹 [步骤 2/3] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered' 已准备就绪。

正在处理文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 0 行。

正在处理文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 1 行。

所有 .jsonl 文件处理完毕！
✅ [步骤 2/3] 过滤完成。结果位于 'filtered_results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria'.
--------------------------------------------------
🔬 [步骤 3/3] 使用 ESM 模型处理序列...
W1022 17:32:44.097000 103458 site-packages/torch/distributed/run.py:774] 
W1022 17:32:44.097000 103458 site-packages/torch/distributed/run.py:774] *****************************************
W1022 17:32:44.097000 103458 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 17:32:44.097000 103458 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.79it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.50it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.32it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.23it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.10it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.40it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.99it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.80it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.86it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.46it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.73it/s]
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1022 17:33:17.773064128 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1022 17:33:17.888459107 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1022 17:33:20.691705690 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1022 17:33:21.892808475 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1022 17:33:21.485446648 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1022 17:33:23.446403358 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1022 17:33:26.480668841 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1022 17:33:29.454994914 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:04,  4.57s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:04<00:00,  2.29s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:04<00:00,  2.29s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 804.05file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 5093.27file/s]
摘要文件成功保存到: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/summary_results.csv
✅ [步骤 3/3] 序列处理完成。
--------------------------------------------------
🔬 [Step 4/3] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 0
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 1
  修改行数: 1

批量处理完毕，共处理 2 个文件。
✅ [Step 4/3] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
开始转换文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.jsonl -> results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 0 个 FASTA 条目。
开始转换文件: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.jsonl -> results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 1 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria'
正在加载 ProtT5 模型...
模型加载完毕。
在路径 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria' 中未找到任何 .fasta 文件。

--- 所有操作执行完毕！结果保存在 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.fasta
Error: No protein IDs found in the FASTA file 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0.fasta'. Please check the file format.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/Bacteria/src/classifying_unknown_proteins.py", line 94, in <module>
    with h5py.File(args.X, "r") as f:
  File "/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/h5py/_hl/files.py", line 533, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/data/nnotaa/miniconda3/envs/ml/lib/python3.10/site-packages/h5py/_hl/files.py", line 226, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 106, in h5py.h5f.open
FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7_per_protein.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7.fasta
Found 1 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7_per_protein.h5

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-22_17-13-02/Qwen_Qwen2.5-7B-Instruct/Bacteria_filtered_esm/temp-0.7_per_protein.jsonl'
✅ 模型 Qwen/Qwen2.5-7B-Instruct 处理完成。
-----------------------------------------
🎉 所有任务执行完毕！
