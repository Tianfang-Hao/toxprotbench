🚀 开始处理模型: grok-3 (标签: api)
   - 清理后的模型名: grok-3
   - 创建输出目录: results/2025-10-23_01-33-47/grok-3
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: grok-3
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/grok-3/Bacteria/raw
  温度: 0.0 0.7
  检测到 'api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: grok-3
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/grok-3/Bacteria/raw
============================================================
统一 API 客户端初始化完成，模型: grok-3，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:05<01:06,  5.54s/it]Temp-0.0 Infer:  23%|██▎       | 3/13 [00:05<00:14,  1.50s/it]Temp-0.0 Infer:  38%|███▊      | 5/13 [00:08<00:11,  1.40s/it]Temp-0.0 Infer:  62%|██████▏   | 8/13 [00:10<00:04,  1.03it/s]Temp-0.0 Infer:  92%|█████████▏| 12/13 [00:11<00:00,  1.48it/s]Temp-0.0 Infer: 100%|██████████| 13/13 [02:11<00:00, 18.75s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [02:11<00:00, 10.13s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/grok-3/Bacteria/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:02<00:34,  2.86s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:04<00:22,  2.05s/it]Temp-0.7 Infer:  23%|██▎       | 3/13 [00:10<00:37,  3.75s/it]Temp-0.7 Infer:  54%|█████▍    | 7/13 [00:10<00:06,  1.07s/it]Temp-0.7 Infer:  92%|█████████▏| 12/13 [00:11<00:00,  1.62it/s]Temp-0.7 Infer: 100%|██████████| 13/13 [00:14<00:00,  1.16it/s]Temp-0.7 Infer: 100%|██████████| 13/13 [00:14<00:00,  1.08s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/grok-3/Bacteria/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 13 行。

正在处理文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 13 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:36:15.597000 208454 site-packages/torch/distributed/run.py:774] 
W1023 01:36:15.597000 208454 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:36:15.597000 208454 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:36:15.597000 208454 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 24.90it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 24.47it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 24.71it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 23.57it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 23.60it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 23.68it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.97it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.75it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:36:27.262566055 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:36:28.824892313 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:36:28.826499818 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:36:28.829788677 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:36:28.829942892 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1023 01:36:28.830002018 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:36:28.011022930 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:36:28.290238532 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 2batch [00:01,  1.06batch/s][A
                                              [A文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.88s/file, 处理中: temp-0.0.jsonl]文件总进度:  50%|█████     | 1/2 [00:01<00:01,  1.88s/file, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 2batch [00:01,  1.29batch/s][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:03<00:00,  1.69s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:03<00:00,  1.72s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 1018.28file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 7390.84file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 13
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 13
  修改行数: 0

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
开始转换文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 13 个 FASTA 条目。
开始转换文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 13 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.fasta ---
读取了 13 条序列。
处理批次 13，包含 13 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
文件 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.fasta 处理完毕，耗时 1.82 秒。

--- 正在处理文件: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.fasta ---
读取了 13 条序列。
处理批次 13，包含 13 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
文件 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.fasta 处理完毕，耗时 1.04 秒。

--- 所有文件处理完毕！总耗时 2.87 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0.fasta
Found 13 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Generate' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7.fasta
Found 13 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Generate' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/grok-3/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl'
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: grok-3
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/grok-3/Animal/raw
  温度: 0.0 0.7
  检测到 'openai-api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: grok-3
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/grok-3/Animal/raw
============================================================
统一 API 客户端初始化完成，模型: grok-3，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:04<00:55,  4.65s/it]Temp-0.0 Infer:  15%|█▌        | 2/13 [00:05<00:25,  2.34s/it]Temp-0.0 Infer:  23%|██▎       | 3/13 [00:05<00:14,  1.45s/it]Temp-0.0 Infer:  38%|███▊      | 5/13 [00:06<00:06,  1.14it/s]Temp-0.0 Infer:  62%|██████▏   | 8/13 [00:36<00:29,  5.87s/it]Temp-0.0 Infer:  92%|█████████▏| 12/13 [06:02<00:30, 30.20s/it]
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/openai/_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 225, in process_single_prompt
    generated_text, finish_reason = client.generate(
                                    ^^^^^^^^^^^^^^^^
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 178, in generate
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/openai/_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 340, in <module>
    main()
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 331, in main
    for output_record in tqdm(results_iterator, total=len(all_prompt_data), desc=f"Temp-{temp} Infer"):
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 235, in process_single_prompt
    if client.is_rate_limit_error(e):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/align-anything/projects/Bio/benchmark/src/batch_inference_api.py", line 196, in is_rate_limit_error
    (isinstance(error, OpenAIAPIError) and error.status_code == 429)
                                           ^^^^^^^^^^^^^^^^^
AttributeError: 'APITimeoutError' object has no attribute 'status_code'
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/grok-3/Animal/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 12 行，保留了 12 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:43:32.260000 210279 site-packages/torch/distributed/run.py:774] 
W1023 01:43:32.260000 210279 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:43:32.260000 210279 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:43:32.260000 210279 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.21it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.84it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.93it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.89it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.22it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.88it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.77it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.04it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.76it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.94it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.34it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:44:05.538116482 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:44:07.959250975 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:44:07.202641877 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:44:08.315960520 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:44:09.674585009 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:44:09.956586458 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:44:09.532071955 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:44:10.548976587 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/1 [00:00<?, ?file/s]文件总进度:   0%|          | 0/1 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 2batch [00:09,  4.84s/batch][A
                                              [A文件总进度: 100%|██████████| 1/1 [00:09<00:00,  9.69s/file, 处理中: temp-0.0.jsonl]文件总进度: 100%|██████████| 1/1 [00:09<00:00,  9.70s/file, 处理中: temp-0.0.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/1 [00:00<?, ?file/s]合并文件: 100%|██████████| 1/1 [00:00<00:00, 148.66file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/1 [00:00<?, ?file/s]生成摘要: 100%|██████████| 1/1 [00:00<00:00, 1716.87file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 12
  修改行数: 0

批量处理完毕，共处理 1 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 165: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 166: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 169: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 176: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 12 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
警告: 未找到文件 results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.7.jsonl
开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv'
警告: 未找到文件 results/2025-10-23_01-33-47/grok-3/Animal/raw_filtered_esm/temp-0.7.jsonl
✅ 模型 grok-3 处理完成。
-----------------------------------------
🚀 开始处理模型: gpt-5 (标签: api)
   - 清理后的模型名: gpt-5
   - 创建输出目录: results/2025-10-23_01-33-47/gpt-5
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: gpt-5
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw
  温度: 0.0 0.7
  检测到 'api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: gpt-5
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw
============================================================
统一 API 客户端初始化完成，模型: gpt-5，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:14<02:52, 14.39s/it]Temp-0.0 Infer:  23%|██▎       | 3/13 [00:18<00:52,  5.26s/it]Temp-0.0 Infer:  31%|███       | 4/13 [00:19<00:32,  3.66s/it]Temp-0.0 Infer:  77%|███████▋  | 10/13 [00:21<00:03,  1.17s/it]Temp-0.0 Infer:  92%|█████████▏| 12/13 [00:26<00:01,  1.51s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [00:26<00:00,  2.01s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:12<02:27, 12.33s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:14<01:06,  6.06s/it]Temp-0.7 Infer:  23%|██▎       | 3/13 [00:17<00:51,  5.11s/it]Temp-0.7 Infer:  92%|█████████▏| 12/13 [00:22<00:01,  1.17s/it]Temp-0.7 Infer: 100%|██████████| 13/13 [00:22<00:00,  1.73s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 6 行。

正在处理文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 8 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:45:55.732000 211483 site-packages/torch/distributed/run.py:774] 
W1023 01:45:55.732000 211483 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:45:55.732000 211483 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:45:55.732000 211483 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.81it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.60it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.07it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.68it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.93it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.21it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.84it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.88it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.73it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.47it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.91it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.31it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.20it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.93it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.05it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:46:23.547467702 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:46:24.219642735 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:46:25.825875645 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:46:25.392591987 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:46:25.440640896 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:46:26.751149855 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:46:26.897500109 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:46:26.092242969 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度: 100%|██████████| 2/2 [00:00<00:00, 582.30file/s, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 559.65file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 2874.78file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 6
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 8
  修改行数: 0

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
开始转换文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 6 个 FASTA 条目。
开始转换文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 8 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.fasta ---
读取了 6 条序列。
处理批次 6，包含 6 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
文件 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.fasta 处理完毕，耗时 0.79 秒。

--- 正在处理文件: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.fasta ---
读取了 8 条序列。
处理批次 8，包含 8 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
文件 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.fasta 处理完毕，耗时 0.36 秒。

--- 所有文件处理完毕！总耗时 1.15 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0.fasta
Found 6 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7.fasta
Found 8 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gpt-5/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl'
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: gpt-5
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/gpt-5/Animal/raw
  温度: 0.0 0.7
  检测到 'openai-api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: gpt-5
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/gpt-5/Animal/raw
============================================================
统一 API 客户端初始化完成，模型: gpt-5，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:13<02:36, 13.02s/it]Temp-0.0 Infer:  23%|██▎       | 3/13 [00:13<00:36,  3.70s/it]Temp-0.0 Infer:  46%|████▌     | 6/13 [00:14<00:10,  1.47s/it]Temp-0.0 Infer:  85%|████████▍ | 11/13 [00:18<00:02,  1.17s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [00:18<00:00,  1.45s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gpt-5/Animal/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:12<02:35, 12.96s/it]Temp-0.7 Infer:  31%|███       | 4/13 [00:15<00:27,  3.09s/it]Temp-0.7 Infer:  62%|██████▏   | 8/13 [00:16<00:06,  1.39s/it]Temp-0.7 Infer:  85%|████████▍ | 11/13 [00:19<00:02,  1.26s/it]Temp-0.7 Infer: 100%|██████████| 13/13 [00:19<00:00,  1.51s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gpt-5/Animal/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/gpt-5/Animal/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 10 行。

正在处理文件: results/2025-10-23_01-33-47/gpt-5/Animal/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 8 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:48:27.375000 213230 site-packages/torch/distributed/run.py:774] 
W1023 01:48:27.375000 213230 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:48:27.375000 213230 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:48:27.375000 213230 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.37it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.68it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.99it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.86it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.41it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.43it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.25it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.62it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.42it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.06it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.99it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.49it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.32it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.61it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.43it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:48:53.326343757 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:48:53.410241873 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:48:53.583629827 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:48:54.843941163 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:48:54.016754416 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:48:54.143056156 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:48:54.379151473 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:48:54.383642222 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度: 100%|██████████| 2/2 [00:00<00:00, 385.91file/s, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 215.93file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 2264.13file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 10
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 8
  修改行数: 0

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 165: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 166: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 169: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 176: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 10 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 165: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 166: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 169: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 176: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 8 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv'
开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gpt-5/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv'
✅ 模型 gpt-5 处理完成。
-----------------------------------------
🚀 开始处理模型: claude-3-7-sonnet-20250219 (标签: api)
   - 清理后的模型名: claude-3-7-sonnet-20250219
   - 创建输出目录: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: claude-3-7-sonnet-20250219
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw
  温度: 0.0 0.7
  检测到 'api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: claude-3-7-sonnet-20250219
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw
============================================================
统一 API 客户端初始化完成，模型: claude-3-7-sonnet-20250219，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:05<01:02,  5.25s/it]Temp-0.0 Infer:  15%|█▌        | 2/13 [00:09<00:49,  4.52s/it]Temp-0.0 Infer:  38%|███▊      | 5/13 [00:09<00:10,  1.34s/it]Temp-0.0 Infer:  62%|██████▏   | 8/13 [00:12<00:05,  1.13s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [00:13<00:00,  1.47it/s]Temp-0.0 Infer: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:03<00:45,  3.76s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:04<00:24,  2.27s/it]Temp-0.7 Infer:  23%|██▎       | 3/13 [00:05<00:16,  1.62s/it]Temp-0.7 Infer:  38%|███▊      | 5/13 [00:07<00:09,  1.23s/it]Temp-0.7 Infer:  62%|██████▏   | 8/13 [00:12<00:07,  1.40s/it]Temp-0.7 Infer: 100%|██████████| 13/13 [00:12<00:00,  1.59it/s]Temp-0.7 Infer: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]
✅ 结果已保存至: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 13 行。

正在处理文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 13 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Bacteria/raw_filtered'.
--------------------------------------------------
错误: 未知的模型标签 'api'。请在主脚本中检查 MODEL_CONFIGS。
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: claude-3-7-sonnet-20250219
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw
  温度: 0.0 0.7
  检测到 'openai-api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: claude-3-7-sonnet-20250219
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw
============================================================
统一 API 客户端初始化完成，模型: claude-3-7-sonnet-20250219，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:04<00:56,  4.73s/it]Temp-0.0 Infer:  31%|███       | 4/13 [00:05<00:08,  1.03it/s]Temp-0.0 Infer:  38%|███▊      | 5/13 [00:08<00:13,  1.71s/it]Temp-0.0 Infer:  62%|██████▏   | 8/13 [00:10<00:05,  1.07s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [00:11<00:00,  1.51it/s]Temp-0.0 Infer: 100%|██████████| 13/13 [00:11<00:00,  1.09it/s]
✅ 结果已保存至: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:04<00:52,  4.36s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:04<00:23,  2.17s/it]Temp-0.7 Infer:  38%|███▊      | 5/13 [00:05<00:06,  1.33it/s]Temp-0.7 Infer:  54%|█████▍    | 7/13 [00:07<00:04,  1.34it/s]Temp-0.7 Infer:  62%|██████▏   | 8/13 [00:07<00:03,  1.43it/s]Temp-0.7 Infer: 100%|██████████| 13/13 [00:09<00:00,  1.82it/s]Temp-0.7 Infer: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s]
✅ 结果已保存至: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 13 行。

正在处理文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 13 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:50:12.118000 215088 site-packages/torch/distributed/run.py:774] 
W1023 01:50:12.118000 215088 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:50:12.118000 215088 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:50:12.118000 215088 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.85it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.21it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.35it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.48it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 20.80it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.16it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.17it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.69it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.96it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:50:24.566143951 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:50:25.502684465 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:50:25.510322965 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1023 01:50:25.510333151 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:50:25.515378768 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:50:25.594649664 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:50:25.610396746 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:50:26.169107808 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:02,  2.94s/batch][A
                                              [A文件总进度:  50%|█████     | 1/2 [00:02<00:02,  2.94s/file, 处理中: temp-0.0.jsonl]文件总进度:  50%|█████     | 1/2 [00:02<00:02,  2.94s/file, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:03,  3.19s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:06<00:00,  3.09s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:06<00:00,  3.07s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 397.21file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 2738.69file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 13
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 13
  修改行数: 0

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 165: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 166: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 169: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 176: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 13 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

Animal/scripts/toxinpred.sh: line 161: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 165: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 166: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 169: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 176: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 13 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.0_toxinpred_results.csv'
开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/claude-3-7-sonnet-20250219/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv'
✅ 模型 claude-3-7-sonnet-20250219 处理完成。
-----------------------------------------
🚀 开始处理模型: gemini-2.5-flash (标签: api)
   - 清理后的模型名: gemini-2.5-flash
   - 创建输出目录: results/2025-10-23_01-33-47/gemini-2.5-flash
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: gemini-2.5-flash
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw
  温度: 0.0 0.7
  检测到 'api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: gemini-2.5-flash
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw
============================================================
统一 API 客户端初始化完成，模型: gemini-2.5-flash，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.0...
🔄 -----------------------------------
Temp-0.0 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.0 Infer:   8%|▊         | 1/13 [00:07<01:27,  7.27s/it]Temp-0.0 Infer:  15%|█▌        | 2/13 [00:07<00:37,  3.40s/it]Temp-0.0 Infer:  62%|██████▏   | 8/13 [00:08<00:03,  1.56it/s]Temp-0.0 Infer:  77%|███████▋  | 10/13 [01:02<00:24,  8.07s/it]Temp-0.0 Infer:  85%|████████▍ | 11/13 [01:06<00:14,  7.48s/it]Temp-0.0 Infer:  92%|█████████▏| 12/13 [01:12<00:07,  7.17s/it]Temp-0.0 Infer: 100%|██████████| 13/13 [01:12<00:00,  5.58s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw/temp-0.0.jsonl

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:05<01:07,  5.60s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:07<00:37,  3.39s/it]Temp-0.7 Infer:  23%|██▎       | 3/13 [00:31<02:09, 12.99s/it]Temp-0.7 Infer:  77%|███████▋  | 10/13 [01:43<00:32, 10.71s/it]Temp-0.7 Infer: 100%|██████████| 13/13 [01:43<00:00,  7.95s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
Bacteria/scripts/exo.sh: line 93: --repetition_penalty: command not found
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
   总共处理 13 行，保留了 8 行。

正在处理文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
   总共处理 13 行，保留了 9 行。

所有 .jsonl 文件处理完毕！输出位于: /data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered'.
--------------------------------------------------
Bacteria/scripts/exo.sh: line 119: --repetition_penalty: command not found
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:54:41.758000 216810 site-packages/torch/distributed/run.py:774] 
W1023 01:54:41.758000 216810 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:54:41.758000 216810 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:54:41.758000 216810 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.47it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.06it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.73it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.57it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.32it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.27it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.82it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.41it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.98it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.99it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.24it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.19it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.59it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  8.77it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 15.26it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:55:02.093391979 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:55:04.730890592 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1023 01:55:04.731192460 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:55:04.818985942 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:55:04.941046406 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:55:04.083766642 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:55:04.126205103 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:55:04.258765872 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
                                          [A文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s][A
Batches (Rank 0): 1batch [00:03,  3.56s/batch][A
                                              [A文件总进度: 100%|██████████| 2/2 [00:03<00:00,  1.78s/file, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:03<00:00,  1.78s/file, 处理中: temp-0.7.jsonl]

所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 321.59file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 3069.38file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 8
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 9
  修改行数: 0

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
开始转换文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 8 个 FASTA 条目。
开始转换文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 9 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.fasta ---
读取了 8 条序列。
处理批次 8，包含 8 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
文件 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.fasta 处理完毕，耗时 0.50 秒。

--- 正在处理文件: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.fasta ---
读取了 9 条序列。
处理批次 9，包含 9 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
文件 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.fasta 处理完毕，耗时 0.11 秒。

--- 所有文件处理完毕！总耗时 0.61 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0.fasta
Found 8 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7.fasta
Found 9 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Generate' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/gemini-2.5-flash/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl'
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: gemini-2.5-flash
  模型标签: api
  输出目录: results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw
  温度: 0.7
  检测到 'openai-api' 标签, 调用 API 推理脚本...
============================================================
🚀 开始 统一API 推理任务 (并发版 v3.3)...
⚡ 最大并发数: 50
 timeout=120s
🤖 API 模型: gemini-2.5-flash
📂 Prompt 文件: dataset/test.jsonl
🔥 温度列表: [0.7]
📝 输出目录: results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw
============================================================
统一 API 客户端初始化完成，模型: gemini-2.5-flash，URL: https://api3.xhub.chat/v1

🔄 -----------------------------------
🔄 正在处理温度: 0.7...
🔄 -----------------------------------
Temp-0.7 Infer:   0%|          | 0/13 [00:00<?, ?it/s]Temp-0.7 Infer:   8%|▊         | 1/13 [00:05<01:10,  5.89s/it]Temp-0.7 Infer:  15%|█▌        | 2/13 [00:54<05:41, 31.06s/it]Temp-0.7 Infer:  77%|███████▋  | 10/13 [00:55<00:12,  4.15s/it]Temp-0.7 Infer: 100%|██████████| 13/13 [00:55<00:00,  4.29s/it]
✅ 结果已保存至: results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw/temp-0.7.jsonl

🎉 所有 API 推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
usage: filter_no_stop.py [-h] [-o OUTPUT_DIR] input_dir
filter_no_stop.py: error: unrecognized arguments: --metric_file 0.0
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:56:57.796000 218378 site-packages/torch/distributed/run.py:774] 
W1023 01:56:57.796000 218378 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:56:57.796000 218378 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:56:57.796000 218378 site-packages/torch/distributed/run.py:774] *****************************************
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
usage: process_sequences.py [-h] --input_folder INPUT_FOLDER
                            [--output_folder OUTPUT_FOLDER]
                            [--summary_csv_name SUMMARY_CSV_NAME]
                            [--model_name MODEL_NAME]
                            [--max_tokens_per_batch MAX_TOKENS_PER_BATCH]
process_sequences.py: error: unrecognized arguments: --metric_file 0.0
W1023 01:57:02.311000 218378 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 218451 closing signal SIGTERM
W1023 01:57:02.311000 218378 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 218457 closing signal SIGTERM
W1023 01:57:02.311000 218378 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 218458 closing signal SIGTERM
E1023 01:57:02.375000 218378 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 2) local_rank: 1 (pid: 218452) of binary: /data/nnotaa/miniconda3/envs/align-anything/bin/python3.11
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/align-anything/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/process_sequences.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-10-23_01:57:02
  host      : lyg0270
  rank      : 2 (local_rank: 2)
  exitcode  : 2 (pid: 218453)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-10-23_01:57:02
  host      : lyg0270
  rank      : 3 (local_rank: 3)
  exitcode  : 2 (pid: 218454)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-10-23_01:57:02
  host      : lyg0270
  rank      : 4 (local_rank: 4)
  exitcode  : 2 (pid: 218455)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-10-23_01:57:02
  host      : lyg0270
  rank      : 5 (local_rank: 5)
  exitcode  : 2 (pid: 218456)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-23_01:57:02
  host      : lyg0270
  rank      : 1 (local_rank: 1)
  exitcode  : 2 (pid: 218452)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
usage: clean_imend.py [-h] [-f FIELD] [-t TOKEN] directory
clean_imend.py: error: unrecognized arguments: --metric_file 0.0
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 167: local: can only be used in a function
警告: 未找到文件 results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw_filtered_esm/temp-0.7.jsonl
警告: 未找到文件 results/2025-10-23_01-33-47/gemini-2.5-flash/Animal/raw_filtered_esm/temp-0.7.jsonl
✅ 模型 gemini-2.5-flash 处理完成。
-----------------------------------------
🚀 开始处理模型: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380 (标签: local)
   - 清理后的模型名: _data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380
   - 创建输出目录: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380
  模型标签: local
  输出目录: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1023 01:57:04.146000 218497 site-packages/torch/distributed/run.py:774] 
W1023 01:57:04.146000 218497 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:57:04.146000 218497 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:57:04.146000 218497 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:57:11.371175211 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:57:11.589185849 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:57:12.806570161 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:57:12.947805315 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:57:12.973213341 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:57:12.986261497 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:57:12.002641878 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl (Key: prompt)
🤖 模型列表: ['/data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen2.5-7B-Instruct_slice_5380...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:57:12.040916359 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:   0%|          | 0/2 [00:01<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:00<00:00,  1.16it/s][A
GPU-0 Infer: 100%|██████████| 2/2 [00:01<00:00,  1.67it/s][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw/temp-0.0.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.0:  50%|█████     | 1/2 [00:58<00:58, 59.00s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7:  50%|█████     | 1/2 [00:58<00:58, 59.00s/it]
GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:00<00:00,  1.95it/s][A
GPU-0 Infer: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw/temp-0.7.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [01:56<00:00, 57.95s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 2/2 [01:56<00:00, 58.10s/it]

🎉 所有推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 5 行。

正在处理文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 8 行。

所有 .jsonl 文件处理完毕！
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered'.
--------------------------------------------------
Bacteria/scripts/exo.sh: line 119: --repetition_penalty: command not found
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 01:59:13.132000 220015 site-packages/torch/distributed/run.py:774] 
W1023 01:59:13.132000 220015 site-packages/torch/distributed/run.py:774] *****************************************
W1023 01:59:13.132000 220015 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 01:59:13.132000 220015 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.63it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.98it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 23.06it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 01:59:25.889966096 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.11it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.84it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 13.09it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.27it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.36it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 01:59:25.402723951 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 01:59:26.300869018 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 01:59:27.252498997 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 01:59:27.292940033 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 01:59:27.328863140 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.92it/s]
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 01:59:28.692064720 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 01:59:30.682219841 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:00<00:00, 3645.64file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s]Batches (Rank 0): 1batch [00:01,  1.39s/batch]                                              
所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 273.38file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 2857.16file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 5
  修改行数: 5

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 8
  修改行数: 8

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
开始转换文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 5 个 FASTA 条目。
开始转换文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 8 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.fasta ---
读取了 5 条序列。
处理批次 5，包含 5 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
文件 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.fasta 处理完毕，耗时 0.73 秒。

--- 正在处理文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.fasta ---
读取了 8 条序列。
处理批次 8，包含 8 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
文件 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.fasta 处理完毕，耗时 0.27 秒。

--- 所有文件处理完毕！总耗时 1.00 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0.fasta
Found 5 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7.fasta
Found 8 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Warning: ID 'Generate' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl'
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380
  模型标签: local
  输出目录: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw
  温度: 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1023 02:00:55.437000 221458 site-packages/torch/distributed/run.py:774] 
W1023 02:00:55.437000 221458 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:00:55.437000 221458 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:00:55.437000 221458 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:01:06.820653481 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:01:06.126822247 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:01:06.255603169 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl (Key: prompt)
🤖 模型列表: ['/data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380']
🔥 温度列表: [0.7]
📝 输出目录: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw
============================================================
总进度:   0%|          | 0/1 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen2.5-7B-Instruct_slice_5380...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:01:06.332770400 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:01:07.644033753 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:01:07.945482806 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:01:07.975355566 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:01:07.987696735 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7:   0%|          | 0/1 [00:01<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:51<00:51, 51.26s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:52<00:00, 21.67s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw/temp-0.7.jsonl
模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 1/1 [02:10<00:00, 130.20s/it]模型: Qwen2.5-7B-Instruct_slice_5380, Temp: 0.7: 100%|██████████| 1/1 [02:10<00:00, 130.20s/it]

🎉 所有推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 7 行。

所有 .jsonl 文件处理完毕！
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 02:03:24.727000 223007 site-packages/torch/distributed/run.py:774] 
W1023 02:03:24.727000 223007 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:03:24.727000 223007 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:03:24.727000 223007 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.87it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.85it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.91it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.88it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.25it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.69it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 18.34it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 18.28it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.25it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.41it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.73it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.55it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.83it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.69it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.56it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.27it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:03:42.874580237 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:03:43.697430914 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:03:43.720432276 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:03:43.802456778 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:03:43.019976209 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:03:43.053738207 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:03:43.447898779 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:03:43.449140394 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/1 [00:00<?, ?file/s]文件总进度:   0%|          | 0/1 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 1/1 [00:00<00:00, 1335.34file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s]Batches (Rank 0): 1batch [00:26, 26.03s/batch]                                              
所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/1 [00:00<?, ?file/s]合并文件: 100%|██████████| 1/1 [00:00<00:00, 712.59file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/1 [00:00<?, ?file/s]生成摘要: 100%|██████████| 1/1 [00:00<00:00, 4871.43file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 7
  修改行数: 7

批量处理完毕，共处理 1 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 167: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 172: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 175: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 177: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 182: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/_data_nnotaa_align-anything_projects_Bio_outputs_Qwen2.5-7B-Instruct_slice_5380/Animal/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 7 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

grep: : No such file or directory
usage: merge_csv_jsonl.py [-h] input_csv input_jsonl output_jsonl
merge_csv_jsonl.py: error: unrecognized arguments: --metric_file 0.0
✅ 模型 /data/nnotaa/align-anything/projects/Bio/outputs/Qwen2.5-7B-Instruct/slice_5380 处理完成。
-----------------------------------------
🚀 开始处理模型: Qwen/Qwen2.5-7B-Instruct (标签: local)
   - 清理后的模型名: Qwen_Qwen2.5-7B-Instruct
   - 创建输出目录: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
   - 正在运行 Bacteria exo prediction 任务...
--- 开始执行推理任务 ---
  模型路径: Qwen/Qwen2.5-7B-Instruct
  模型标签: local
  输出目录: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw
  温度: 0.0 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1023 02:04:25.818000 223863 site-packages/torch/distributed/run.py:774] 
W1023 02:04:25.818000 223863 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:04:25.818000 223863 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:04:25.818000 223863 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:04:33.202043941 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:04:33.515062284 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:04:34.782609290 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:04:34.803321572 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:04:34.827205287 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl (Key: prompt)
🤖 模型列表: ['Qwen/Qwen2.5-7B-Instruct']
🔥 温度列表: [0.0, 0.7]
📝 输出目录: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw
============================================================
总进度:   0%|          | 0/2 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen_Qwen2.5-7B-Instruct...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:04:34.860256990 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:04:34.892800437 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:04:34.899231937 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:   0%|          | 0/2 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 99.10it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 100.19it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.89it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 101.55it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 100.87it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.47it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.17it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.86it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][AThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.

GPU-0 Infer:  50%|█████     | 1/2 [00:22<00:22, 22.24s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:44<00:00, 21.99s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw/temp-0.0.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.0:  50%|█████     | 1/2 [00:55<00:55, 55.73s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7:  50%|█████     | 1/2 [00:55<00:55, 55.73s/it]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.07it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.73it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.81it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.42it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.47it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.76it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.34it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.48it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:00<00:00,  1.76it/s][A
GPU-0 Infer: 100%|██████████| 2/2 [00:23<00:00, 13.44s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw/temp-0.7.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [01:57<00:00, 59.46s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 2/2 [01:57<00:00, 58.90s/it]

🎉 所有推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw/temp-0.0.jsonl
处理完成: 'temp-0.0.jsonl'。
  总共处理 13 行，保留了 0 行。

正在处理文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 1 行。

所有 .jsonl 文件处理完毕！
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered'.
--------------------------------------------------
Bacteria/scripts/exo.sh: line 119: --repetition_penalty: command not found
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 02:06:35.749000 225516 site-packages/torch/distributed/run.py:774] 
W1023 02:06:35.749000 225516 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:06:35.749000 225516 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:06:35.749000 225516 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.29it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.58it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.60it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.30it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.01it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.40it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.28it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.56it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.22it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.94it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  5.92it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.84it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.29it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.06it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.00it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.44it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:06:54.163662504 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:06:55.942791785 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:06:55.219122693 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:06:55.222785828 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:06:55.397606139 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:06:56.028796567 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:06:56.314494573 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:06:57.082648141 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/2 [00:00<?, ?file/s]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.0.jsonl]文件总进度:   0%|          | 0/2 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 2/2 [00:00<00:00, 1525.76file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s]Batches (Rank 0): 1batch [00:05,  5.05s/batch]                                              
所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/2 [00:00<?, ?file/s]合并文件: 100%|██████████| 2/2 [00:00<00:00, 937.59file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/2 [00:00<?, ?file/s]生成摘要: 100%|██████████| 2/2 [00:00<00:00, 4616.74file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.jsonl ---
处理完成: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.jsonl (已覆盖)
  总行数: 0
  修改行数: 0

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 1
  修改行数: 1

批量处理完毕，共处理 2 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
--- 推理任务结束 ---
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
Bacteria/scripts/exo.sh: line 156: --metric_file: command not found
开始转换文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.jsonl -> results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta

转换完成！
成功写入 0 个 FASTA 条目。
开始转换文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 1 个 FASTA 条目。
--- 步骤 1: 正在安装所需的 Python 库... ---
Requirement already satisfied: torch in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (2.8.0)
Requirement already satisfied: transformers in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (4.56.1)
Requirement already satisfied: sentencepiece in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (0.2.1)
Requirement already satisfied: h5py in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (3.14.0)
Requirement already satisfied: filelock in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions>=4.10.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (4.15.0)
Requirement already satisfied: sympy>=1.13.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.5)
Requirement already satisfied: jinja2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: triton==3.4.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from torch) (3.4.0)
Requirement already satisfied: setuptools>=40.8.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from triton==3.4.0->torch) (78.1.1)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.34.4)
Requirement already satisfied: numpy>=1.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.2.6)
Requirement already satisfied: packaging>=20.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml>=5.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2025.9.1)
Requirement already satisfied: requests in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (2.32.5)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from transformers) (4.67.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)
Requirement already satisfied: charset_normalizer<4,>=2 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)

--- 步骤 2: 正在创建所有目录... ---
目录已准备就绪。

--- 步骤 3: 正在检查并下载所需文件... ---
二级结构模型已存在，跳过下载。

--- 步骤 4: 环境准备就绪，正在启动 Python 脚本... ---
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Using device: cuda
检测到输入是一个目录: 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm'
正在加载 ProtT5 模型...
模型加载完毕。
找到 2 个 FASTA 文件，准备开始处理...

--- 正在处理文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta ---
文件 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta 为空或格式不正确，已跳过。

--- 正在处理文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.fasta ---
读取了 1 条序列。
处理批次 1，包含 1 条序列...
正在保存每个蛋白质的嵌入向量至: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
文件 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.fasta 处理完毕，耗时 0.40 秒。

--- 所有文件处理完毕！总耗时 0.40 秒 ---

--- 所有操作执行完毕！结果保存在 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm' 目录中。 ---
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0_per_protein.h5 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta
Error: No protein IDs found in the FASTA file 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0.fasta'. Please check the file format.

<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.

ERROR conda.cli.main_run:execute(127): `conda run python Bacteria/src/classifying_unknown_proteins.py Bacteria/Predictor/sklearn_svcPC20_SST30_CV10_embeddingsProtT5 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5 results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.fasta` failed. (See above for error)
Reading protein ID order from: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7.fasta
Found 1 protein IDs in FASTA file.
Loading embeddings from: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7_per_protein.h5
Warning: ID 'Design' not found in H5 embeddings file (even after normalization). It will be skipped.
Error: No matching protein IDs found between the FASTA file and the H5 file. Cannot proceed.

开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.0_per_protein.jsonl'
开始处理...
  - 从 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
  - 从 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl' 提取字段: ['prediction', 'probability']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Bacteria/raw_filtered_esm/temp-0.7_per_protein.jsonl'
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
   - 正在运行 Animal toxin prediction 任务...
--- 开始执行推理任务 ---
  模型路径: Qwen/Qwen2.5-7B-Instruct
  模型标签: local
  输出目录: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw
  温度: 0.7
  检测到 'local' 标签, 调用本地分布式推理脚本...
W1023 02:07:59.103000 227220 site-packages/torch/distributed/run.py:774] 
W1023 02:07:59.103000 227220 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:07:59.103000 227220 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:07:59.103000 227220 site-packages/torch/distributed/run.py:774] *****************************************
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:08:11.784305213 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
============================================================
🚀 开始分布式推理任务，共 8 个 GPU。
📂 Prompt 文件: dataset/test.jsonl (Key: prompt)
🤖 模型列表: ['Qwen/Qwen2.5-7B-Instruct']
🔥 温度列表: [0.7]
📝 输出目录: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw
============================================================
总进度:   0%|          | 0/1 [00:00<?, ?it/s]
🔄 正在加载模型: Qwen_Qwen2.5-7B-Instruct...
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:08:11.171173812 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:08:12.768699533 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:08:12.786076380 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:08:12.837435913 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:08:12.861435984 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:08:12.868046720 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:08:12.874750991 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7:   0%|          | 0/1 [00:02<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 77.35it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 69.38it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 63.35it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 46.61it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 48.64it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 47.15it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 71.33it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 75.26it/s]

GPU-0 Infer:   0%|          | 0/2 [00:00<?, ?it/s][A
GPU-0 Infer:  50%|█████     | 1/2 [00:01<00:01,  1.60s/it][A
GPU-0 Infer: 100%|██████████| 2/2 [00:38<00:00, 22.43s/it][A
                                                          [A
✅ 结果已保存至: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw/temp-0.7.jsonl
模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 1/1 [01:59<00:00, 119.57s/it]模型: Qwen_Qwen2.5-7B-Instruct, Temp: 0.7: 100%|██████████| 1/1 [01:59<00:00, 119.57s/it]

🎉 所有推理任务完成！
✅ [Step 1/5] 批量推理完成。
--------------------------------------------------
🧹 [Step 3/5] 过滤结果...
输出目录 '/data/nnotaa/align-anything/projects/Bio/benchmark/results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered' 已准备就绪。

正在处理文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw/temp-0.7.jsonl
处理完成: 'temp-0.7.jsonl'。
  总共处理 13 行，保留了 2 行。

所有 .jsonl 文件处理完毕！
✅ [Step 3/5] 过滤完成。结果位于 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered'.
--------------------------------------------------
🔬 [Step 4/5] 使用 ESM 模型处理序列...
W1023 02:10:19.842000 228786 site-packages/torch/distributed/run.py:774] 
W1023 02:10:19.842000 228786 site-packages/torch/distributed/run.py:774] *****************************************
W1023 02:10:19.842000 228786 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1023 02:10:19.842000 228786 site-packages/torch/distributed/run.py:774] *****************************************
高性能模式启动。共 8 个GPU。
最大Tokens/批次: 8192
自动混合精度(autocast)已【禁用】。
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.62it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.28it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.45it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.19it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.24it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.57it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.25it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.70it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.49it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.56it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.01it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  7.01it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.95it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.47it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.14it/s]
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank5]:[W1023 02:10:46.254952017 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank4]:[W1023 02:10:46.268364148 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W1023 02:10:47.905466338 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Rank 0 模型加载完成。
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W1023 02:10:47.946825809 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank6]:[W1023 02:10:47.025399466 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W1023 02:10:48.916292558 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank7]:[W1023 02:10:50.124716139 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/data/nnotaa/miniconda3/envs/align-anything/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W1023 02:10:52.668247802 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
文件总进度:   0%|          | 0/1 [00:00<?, ?file/s]文件总进度:   0%|          | 0/1 [00:00<?, ?file/s, 处理中: temp-0.7.jsonl]文件总进度: 100%|██████████| 1/1 [00:00<00:00, 1246.08file/s, 处理中: temp-0.7.jsonl]
Batches (Rank 0): 0batch [00:00, ?batch/s]Batches (Rank 0): 1batch [00:01,  1.83s/batch]                                              
所有进程计算完成，等待同步...
开始合并临时文件...
合并文件:   0%|          | 0/1 [00:00<?, ?file/s]合并文件: 100%|██████████| 1/1 [00:00<00:00, 622.85file/s]
正在生成最终的CSV摘要文件...
生成摘要:   0%|          | 0/1 [00:00<?, ?file/s]生成摘要: 100%|██████████| 1/1 [00:00<00:00, 3748.26file/s]
摘要文件成功保存到: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/summary_results.csv
✅ [Step 4/5] 序列处理完成。
--------------------------------------------------
🔬 [Step 5/5] cleaning <|im_end|>...
*** 警告：脚本将直接覆盖原始文件，请确保已备份！ ***

开始批量处理文件夹: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm
目标字段: assistant
移除标记: <|im_end|>

--- 正在处理 (将覆盖): results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7.jsonl ---
处理完成: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7.jsonl (已覆盖)
  总行数: 2
  修改行数: 2

批量处理完毕，共处理 1 个文件。
✅ [Step 5/5] <|im_end|> cleaning completed.
--------------------------------------------------
Animal/scripts/toxinpred.sh: line 167: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 171: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 172: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 175: local: can only be used in a function
Animal/scripts/toxinpred.sh: line 177: [: : integer expression expected
Animal/scripts/toxinpred.sh: line 182: [: : integer expression expected
开始转换文件: results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7.jsonl -> results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7.fasta

转换完成！
成功写入 2 个 FASTA 条目。
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
<frozen importlib._bootstrap>:488: Warning: OpenSSL 3's legacy provider failed to load. Legacy algorithms will not be available. If you need those algorithms, check your OpenSSL configuration.
Traceback (most recent call last):
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/bin/toxinpred2", line 7, in <module>
    sys.exit(main())
  File "/data/nnotaa/miniconda3/envs/toxinpred2_env/lib/python3.9/site-packages/toxinpred2/python_scripts/toxinpred2.py", line 300, in main
    f=open(Sequence,"r")
FileNotFoundError: [Errno 2] No such file or directory: ''

ERROR conda.cli.main_run:execute(127): `conda run toxinpred2 -i  -o  -t 0.6 -m 1 -d 2` failed. (See above for error)
##############################################################################
# The program ToxinPred2.0 is developed for predicting Toxin and non toxin #
# protein from their primary sequence, developed by Prof G. P. S. Raghava's group. #
# ############################################################################
Summary of Parameters:
Input File:   ; Model:  1 ; Threshold:  0.6
Output File:   ; Display:  2

grep: : No such file or directory
开始处理...
  - 从 CSV 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv' 提取字段: ['ML_Score', 'Prediction']
  - 从 JSONL 'dataset/test.jsonl' 提取字段: ['id', 'description', 'sequence', 'taxonomy', 'prompt']
错误: 文件未找到 - [Errno 2] No such file or directory: 'results/2025-10-23_01-33-47/Qwen_Qwen2.5-7B-Instruct/Animal/raw_filtered_esm/temp-0.7_toxinpred_results.csv'
✅ 模型 Qwen/Qwen2.5-7B-Instruct 处理完成。
-----------------------------------------
scripts/run.sh: line 80: ash: command not found
📊 生成指标汇总报告...
===== Benchmark Summary =====

[Animal ToxinPred] files=0 rows=0 tox=0 non-tox=0 toxicity_rate=0.000
[Bacteria Classifier] files=0 rows=0 tox=0 non-tox=0 toxicity_rate=0.000

===== End =====
✅ 模型 Qwen/Qwen2.5-7B-Instruct 处理完成。
-----------------------------------------
scripts/run.sh: line 94: syntax error near unexpected token `done'
scripts/run.sh: line 94: `done'
